{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Colab NB Setup"
      ],
      "metadata": {
        "id": "uvM1YpePkLMx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z1wjAGavh9L7",
        "outputId": "afad8f70-91a2-4dda-adf7-a41d3ac60ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/hackathon\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.204)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.17)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.12/dist-packages (1.2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.8.3)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.3)\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (to save your work)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create working directory\n",
        "!mkdir -p /content/drive/MyDrive/hackathon\n",
        "%cd /content/drive/MyDrive/hackathon\n",
        "\n",
        "# Install required libraries\n",
        "!pip install ultralytics  # YOLOv8\n",
        "!pip install roboflow     # Optional: if using Roboflow datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C2A main dataset download"
      ],
      "metadata": {
        "id": "e2pxMSlwkVZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You already uploaded kaggle.json earlier, so skip that step\n",
        "\n",
        "# Move to Colab temp storage (faster)\n",
        "%cd /content\n",
        "\n",
        "# Setup Kaggle credentials (if not already done)\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/hackathon/kaggle.json ~/.kaggle/ 2>/dev/null || echo \"kaggle.json already configured\"\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download C2A to temp storage\n",
        "!kaggle datasets download -d rgbnihal/c2a-dataset\n",
        "!unzip -q c2a-dataset.zip -d datasets/c2a\n",
        "# Create the directory first\n",
        "!mkdir -p datasets/c2a\n",
        "\n",
        "# Then unzip\n",
        "!unzip -q c2a-dataset.zip -d datasets/c2a\n",
        "\n",
        "# Check structure\n",
        "!ls -la datasets/c2a\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5mPmKCwjhC8",
        "outputId": "23e7acb9-81fe-4f2f-b5a1-6bcb628fc2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Dataset URL: https://www.kaggle.com/datasets/rgbnihal/c2a-dataset\n",
            "License(s): MIT\n",
            "c2a-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "checkdir:  cannot create extraction directory: datasets/c2a\n",
            "           No such file or directory\n",
            "total 16\n",
            "drwxr-xr-x 4 root root 4096 Oct  5 01:28 .\n",
            "drwxr-xr-x 3 root root 4096 Oct  5 01:26 ..\n",
            "drwxr-xr-x 3 root root 4096 Oct  5 01:26 C2A_Dataset\n",
            "drwxr-xr-x 2 root root 4096 Oct  5 01:28 Coco_annotation_pose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check C2A_Dataset structure\n",
        "print(\"C2A_Dataset contents:\")\n",
        "!ls -la datasets/c2a/C2A_Dataset\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Coco_annotation_pose contents:\")\n",
        "!ls -la datasets/c2a/Coco_annotation_pose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0zlttvN_P_4",
        "outputId": "99287333-5403-4d58-8832-5c9211c58404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C2A_Dataset contents:\n",
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Oct  5 01:26 .\n",
            "drwxr-xr-x 4 root root 4096 Oct  5 01:28 ..\n",
            "drwxr-xr-x 6 root root 4096 Oct  5 01:28 new_dataset3\n",
            "\n",
            "============================================================\n",
            "Coco_annotation_pose contents:\n",
            "total 49208\n",
            "drwxr-xr-x 2 root root     4096 Oct  5 01:28 .\n",
            "drwxr-xr-x 4 root root     4096 Oct  5 01:28 ..\n",
            "-rw-r--r-- 1 root root 10088565 Sep 18  2024 test_annotations_with_pose_information.json\n",
            "-rw-r--r-- 1 root root 30247742 Sep 18  2024 train_annotations_with_pose_information.json\n",
            "-rw-r--r-- 1 root root 10036783 Sep 18  2024 val_annotations_with_pose_information.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# COCO to YOLO Conversion Script\n",
        "def convert_coco_to_yolo(coco_json_path, images_dir, output_dir):\n",
        "    \"\"\"Convert COCO format annotations to YOLO format\"\"\"\n",
        "\n",
        "    # Load COCO JSON\n",
        "    with open(coco_json_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Build image_id to filename mapping\n",
        "    images_dict = {img['id']: img for img in coco_data['images']}\n",
        "\n",
        "    # Build category mapping (we only care about 'person' class)\n",
        "    # YOLO uses class 0 for person\n",
        "    category_map = {}\n",
        "    for cat in coco_data['categories']:\n",
        "        if cat['name'].lower() == 'person':\n",
        "            category_map[cat['id']] = 0\n",
        "\n",
        "    # Process annotations\n",
        "    annotations_by_image = {}\n",
        "    for ann in coco_data['annotations']:\n",
        "        img_id = ann['image_id']\n",
        "        if img_id not in annotations_by_image:\n",
        "            annotations_by_image[img_id] = []\n",
        "        annotations_by_image[img_id].append(ann)\n",
        "\n",
        "    # Convert each image's annotations\n",
        "    converted_count = 0\n",
        "    for img_id, anns in tqdm(annotations_by_image.items()):\n",
        "        if img_id not in images_dict:\n",
        "            continue\n",
        "\n",
        "        img_info = images_dict[img_id]\n",
        "        img_width = img_info['width']\n",
        "        img_height = img_info['height']\n",
        "        img_filename = img_info['file_name']\n",
        "\n",
        "        # Create YOLO format txt file\n",
        "        txt_filename = Path(img_filename).stem + '.txt'\n",
        "        txt_path = os.path.join(output_dir, txt_filename)\n",
        "\n",
        "        with open(txt_path, 'w') as f:\n",
        "            for ann in anns:\n",
        "                cat_id = ann['category_id']\n",
        "                if cat_id not in category_map:\n",
        "                    continue  # Skip non-person annotations\n",
        "\n",
        "                # COCO bbox: [x, y, width, height] (top-left corner)\n",
        "                # YOLO bbox: [x_center, y_center, width, height] (normalized 0-1)\n",
        "                bbox = ann['bbox']\n",
        "                x, y, w, h = bbox\n",
        "\n",
        "                # Convert to YOLO format\n",
        "                x_center = (x + w / 2) / img_width\n",
        "                y_center = (y + h / 2) / img_height\n",
        "                width = w / img_width\n",
        "                height = h / img_height\n",
        "\n",
        "                # Write in YOLO format: class x_center y_center width height\n",
        "                f.write(f\"{category_map[cat_id]} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "\n",
        "        converted_count += 1\n",
        "\n",
        "    print(f\"✓ Converted {converted_count} images\")\n",
        "    return converted_count\n",
        "\n",
        "# Check images location first\n",
        "print(\"Checking image locations...\")\n",
        "!ls datasets/c2a/C2A_Dataset/new_dataset3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRXJyffCDwi_",
        "outputId": "029d9a63-0a56-4dde-898f-73a160fe189a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking image locations...\n",
            "'All labels with Pose information'   test   train   val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the actual image folders\n",
        "print(\"Train images:\")\n",
        "!ls datasets/c2a/C2A_Dataset/new_dataset3/train | head -5\n",
        "\n",
        "print(\"\\nVal images:\")\n",
        "!ls datasets/c2a/C2A_Dataset/new_dataset3/val | head -5\n",
        "\n",
        "print(\"\\nTest images:\")\n",
        "!ls datasets/c2a/C2A_Dataset/new_dataset3/test | head -5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lvc9RbPEEge",
        "outputId": "e54bd910-20dd-4973-c863-0d20e6b3823a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images:\n",
            "images\n",
            "labels\n",
            "train_annotations.json\n",
            "\n",
            "Val images:\n",
            "images\n",
            "labels\n",
            "val_annotations.json\n",
            "\n",
            "Test images:\n",
            "images\n",
            "labels\n",
            "test_annotations.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if labels already exist in YOLO format\n",
        "print(\"Checking train labels:\")\n",
        "!ls datasets/c2a/C2A_Dataset/new_dataset3/train/labels | head -5\n",
        "\n",
        "print(\"\\nChecking if they're YOLO format (.txt files):\")\n",
        "!head -3 datasets/c2a/C2A_Dataset/new_dataset3/train/labels/*.txt 2>/dev/null | head -10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7MexVWJERzc",
        "outputId": "9e8b8b3b-bf21-4b14-ddcc-6cf1ab33691e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking train labels:\n",
            "collapsed_building_image0001_0.txt\n",
            "collapsed_building_image0001_1.txt\n",
            "collapsed_building_image0001_2.txt\n",
            "collapsed_building_image0001_4.txt\n",
            "collapsed_building_image0002_0.txt\n",
            "\n",
            "Checking if they're YOLO format (.txt files):\n",
            "==> datasets/c2a/C2A_Dataset/new_dataset3/train/labels/collapsed_building_image0001_0.txt <==\n",
            "0 0.017794 0.307292 0.014235 0.038194\n",
            "0 0.854093 0.951389 0.042705 0.062500\n",
            "0 0.450178 0.559028 0.039146 0.034722\n",
            "\n",
            "==> datasets/c2a/C2A_Dataset/new_dataset3/train/labels/collapsed_building_image0001_1.txt <==\n",
            "0 0.250890 0.730903 0.024911 0.052083\n",
            "0 0.932384 0.904514 0.007117 0.017361\n",
            "0 0.386121 0.605903 0.010676 0.010417\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create proper YOLO directory structure\n",
        "!mkdir -p datasets/c2a_yolo/train/images\n",
        "!mkdir -p datasets/c2a_yolo/train/labels\n",
        "!mkdir -p datasets/c2a_yolo/valid/images\n",
        "!mkdir -p datasets/c2a_yolo/valid/labels\n",
        "!mkdir -p datasets/c2a_yolo/test/images\n",
        "!mkdir -p datasets/c2a_yolo/test/labels\n",
        "\n",
        "# Copy/move files to proper structure\n",
        "print(\"Organizing train set...\")\n",
        "!cp -r datasets/c2a/C2A_Dataset/new_dataset3/train/images/* datasets/c2a_yolo/train/images/\n",
        "!cp -r datasets/c2a/C2A_Dataset/new_dataset3/train/labels/* datasets/c2a_yolo/train/labels/\n",
        "\n",
        "print(\"Organizing validation set...\")\n",
        "!cp -r datasets/c2a/C2A_Dataset/new_dataset3/val/images/* datasets/c2a_yolo/valid/images/\n",
        "!cp -r datasets/c2a/C2A_Dataset/new_dataset3/val/labels/* datasets/c2a_yolo/valid/labels/\n",
        "\n",
        "print(\"Organizing test set...\")\n",
        "!cp -r datasets/c2a/C2A_Dataset/new_dataset3/test/images/* datasets/c2a_yolo/test/images/\n",
        "!cp -r datasets/c2a/C2A_Dataset/new_dataset3/test/labels/* datasets/c2a_yolo/test/labels/\n",
        "\n",
        "# Create data.yaml for YOLO\n",
        "data_yaml = \"\"\"\n",
        "path: /content/datasets/c2a_yolo\n",
        "train: train/images\n",
        "val: valid/images\n",
        "test: test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['person']\n",
        "\"\"\"\n",
        "\n",
        "with open('datasets/c2a_yolo/data.yaml', 'w') as f:\n",
        "    f.write(data_yaml)\n",
        "\n",
        "print(\"\\n✓ C2A dataset ready for training!\")\n",
        "\n",
        "# Verify counts\n",
        "!echo \"Train images:\" && ls datasets/c2a_yolo/train/images | wc -l\n",
        "!echo \"Valid images:\" && ls datasets/c2a_yolo/valid/images | wc -l\n",
        "!echo \"Test images:\" && ls datasets/c2a_yolo/test/images | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To3w3DHjEbKG",
        "outputId": "02495b09-c0c0-4ba1-e8a4-22aa07d9b4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Organizing train set...\n",
            "Organizing validation set...\n",
            "Organizing test set...\n",
            "\n",
            "✓ C2A dataset ready for training!\n",
            "Train images:\n",
            "6129\n",
            "Valid images:\n",
            "2043\n",
            "Test images:\n",
            "2043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus Datasets Downloads"
      ],
      "metadata": {
        "id": "V5IWTuG6kcKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "# Initialize with your API key\n",
        "rf = Roboflow(api_key=\"QPJAFMFqwQriB5Vfm8gu\")\n",
        "\n",
        "# Download thermal dataset - use hyphens instead of spaces\n",
        "print(\"Downloading thermal dataset...\")\n",
        "thermal_project = rf.workspace(\"myworkspace-x1jig\").project(\"thermal-person-df3lf-xu4ws\")\n",
        "thermal_dataset = thermal_project.version(1).download(\"yolov8\", location=\"datasets/thermal\")\n",
        "\n",
        "# Download aerial dataset\n",
        "print(\"Downloading aerial dataset...\")\n",
        "aerial_project = rf.workspace(\"myworkspace-x1jig\").project(\"drone-person-detection-ald8g-ku6nj\")\n",
        "aerial_dataset = aerial_project.version(1).download(\"yolov8\", location=\"datasets/aerial\")\n",
        "\n",
        "print(\"\\n✓ All datasets downloaded!\")"
      ],
      "metadata": {
        "id": "f9ojA8GIkiKn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "5fb0297e-f425-456c-e426-10d7b9d7154b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading thermal dataset...\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in datasets/thermal to yolov8:: 100%|██████████| 173772/173772 [00:04<00:00, 36866.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to datasets/thermal in yolov8::   3%|▎         | 265/8962 [00:00<00:02, 2998.31it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2748991056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading thermal dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mthermal_project\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"myworkspace-x1jig\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"thermal-person-df3lf-xu4ws\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mthermal_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthermal_project\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolov8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"datasets/thermal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Download aerial dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/roboflow/core/version.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, model_format, location, overwrite)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__download_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__extract_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reformat_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_format\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: is roboflow-python a place to be munging yaml files?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/roboflow/core/version.py\u001b[0m in \u001b[0;36m__extract_zip\u001b[0;34m(self, location, format)\u001b[0m\n\u001b[1;32m    586\u001b[0m             ):\n\u001b[1;32m    587\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m                     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error unzipping download\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, pwd)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_samefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "verify data structure"
      ],
      "metadata": {
        "id": "B1Obk44E1exq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DATASET VERIFICATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "datasets = {\n",
        "    'C2A': 'datasets/c2a',\n",
        "    'Thermal': 'datasets/thermal',\n",
        "    'Aerial': 'datasets/aerial'\n",
        "}\n",
        "\n",
        "for name, path in datasets.items():\n",
        "    print(f\"\\n{name} Dataset:\")\n",
        "    if os.path.exists(path):\n",
        "        # Count train images\n",
        "        train_path = f\"{path}/train/images\" if os.path.exists(f\"{path}/train/images\") else f\"{path}/images\"\n",
        "        if os.path.exists(train_path):\n",
        "            train_count = len([f for f in os.listdir(train_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "            print(f\"  ✓ Train images: {train_count}\")\n",
        "\n",
        "        # Count validation images\n",
        "        valid_path = f\"{path}/valid/images\" if os.path.exists(f\"{path}/valid/images\") else None\n",
        "        if valid_path and os.path.exists(valid_path):\n",
        "            valid_count = len([f for f in os.listdir(valid_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "            print(f\"  ✓ Valid images: {valid_count}\")\n",
        "\n",
        "        # Check for data.yaml\n",
        "        if os.path.exists(f\"{path}/data.yaml\"):\n",
        "            print(f\"  ✓ data.yaml found\")\n",
        "\n",
        "        # Check annotation format\n",
        "        labels_path = f\"{path}/train/labels\" if os.path.exists(f\"{path}/train/labels\") else f\"{path}/labels\"\n",
        "        if os.path.exists(labels_path):\n",
        "            print(f\"  ✓ Labels in YOLO format\")\n",
        "    else:\n",
        "        print(f\"  ✗ NOT FOUND\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQK3I3pJ1giV",
        "outputId": "2c52f68d-8284-448a-a94e-cc9d442d72c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATASET VERIFICATION\n",
            "============================================================\n",
            "\n",
            "C2A Dataset:\n",
            "  ✗ NOT FOUND\n",
            "\n",
            "Thermal Dataset:\n",
            "\n",
            "Aerial Dataset:\n",
            "  ✓ Train images: 935\n",
            "  ✓ Valid images: 274\n",
            "  ✓ data.yaml found\n",
            "  ✓ Labels in YOLO format\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}